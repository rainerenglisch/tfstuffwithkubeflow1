{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager().update('notebook', {'limit_output': 1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "rm -rf models\n",
    "rm -rf TF_obj_detection_original\n",
    "rm -rf ~/.local/share/Trash/*\n",
    "echo \"Cleaned\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already up-to-date: pip in /opt/conda/lib/python3.6/site-packages (19.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
      "\u001b[K     |████████████████████████████████| 109.2MB 63.8MB/s eta 0:00:01    |█████████████████████████▋      | 87.5MB 63.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel>=0.26 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/10/44230dd6bf3563b8f227dbf344c908d412ad2ff48066476672f3a72e174e/wheel-0.33.4-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 50.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 35.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow)\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 32.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 30.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 40.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.1 (from tensorflow)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/0e/e7cdff89745986c984ba58e6ff6541bc5c388dd9ab9d7d312b3b1532584a/protobuf-3.9.0-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 43.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/5d/b434403adb2db8853a97828d3d19f2032e79d630e0d11a8e95d243103a11/grpcio-1.22.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2MB 35.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.10.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting numpy<2.0,>=1.14.5 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/b9/bda9781f0a74b90ebd2e046fde1196182900bd4a8e1ea503d3ffebc50e7c/numpy-1.17.0-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n",
      "\u001b[K     |████████████████████████████████| 20.4MB 33.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting h5py (from keras-applications>=1.0.6->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8MB 34.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 40.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting setuptools>=41.0.0 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/51/f45cea425fd5cb0b0380f5b0f048ebc1da5b417e48d304838c02d6288a1e/setuptools-41.0.1-py2.py3-none-any.whl (575kB)\n",
      "\u001b[K     |████████████████████████████████| 583kB 51.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/ab/d3bed6b92042622d24decc7aadc8877badf18aeca1571045840ad4956d3f/Werkzeug-0.15.5-py2.py3-none-any.whl (328kB)\n",
      "\u001b[K     |████████████████████████████████| 337kB 52.9MB/s eta 0:00:01\n",
      "\u001b[31mERROR: kfp 0.1 has requirement google-cloud-storage==1.13.0, but you'll have google-cloud-storage 1.14.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kfp 0.1 has requirement kubernetes==8.0.0, but you'll have kubernetes 9.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wheel, six, absl-py, gast, tensorflow-estimator, google-pasta, termcolor, numpy, keras-preprocessing, h5py, keras-applications, setuptools, protobuf, markdown, grpcio, werkzeug, tensorboard, wrapt, astor, tensorflow\n",
      "  Found existing installation: wheel 0.33.4\n",
      "    Uninstalling wheel-0.33.4:\n",
      "      Successfully uninstalled wheel-0.33.4\n",
      "  Found existing installation: six 1.12.0\n",
      "    Uninstalling six-1.12.0:\n",
      "      Successfully uninstalled six-1.12.0\n",
      "  Found existing installation: absl-py 0.7.1\n",
      "    Uninstalling absl-py-0.7.1:\n",
      "      Successfully uninstalled absl-py-0.7.1\n",
      "  Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "  Found existing installation: tensorflow-estimator 1.14.0\n",
      "    Uninstalling tensorflow-estimator-1.14.0:\n",
      "      Successfully uninstalled tensorflow-estimator-1.14.0\n",
      "  Found existing installation: google-pasta 0.1.7\n",
      "    Uninstalling google-pasta-0.1.7:\n",
      "      Successfully uninstalled google-pasta-0.1.7\n",
      "  Found existing installation: termcolor 1.1.0\n",
      "    Uninstalling termcolor-1.1.0:\n",
      "      Successfully uninstalled termcolor-1.1.0\n",
      "  Found existing installation: numpy 1.17.0\n",
      "    Uninstalling numpy-1.17.0:\n",
      "      Successfully uninstalled numpy-1.17.0\n",
      "  Found existing installation: Keras-Preprocessing 1.1.0\n",
      "    Uninstalling Keras-Preprocessing-1.1.0:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.0\n",
      "  Found existing installation: h5py 2.9.0\n",
      "    Uninstalling h5py-2.9.0:\n",
      "      Successfully uninstalled h5py-2.9.0\n",
      "  Found existing installation: Keras-Applications 1.0.8\n",
      "    Uninstalling Keras-Applications-1.0.8:\n",
      "      Successfully uninstalled Keras-Applications-1.0.8\n",
      "  Found existing installation: setuptools 41.0.1\n",
      "    Uninstalling setuptools-41.0.1:\n",
      "      Successfully uninstalled setuptools-41.0.1\n",
      "  Found existing installation: protobuf 3.9.0\n",
      "    Uninstalling protobuf-3.9.0:\n",
      "      Successfully uninstalled protobuf-3.9.0\n",
      "  Found existing installation: Markdown 3.1.1\n",
      "    Uninstalling Markdown-3.1.1:\n",
      "      Successfully uninstalled Markdown-3.1.1\n",
      "  Found existing installation: grpcio 1.22.0\n",
      "    Uninstalling grpcio-1.22.0:\n",
      "      Successfully uninstalled grpcio-1.22.0\n",
      "  Found existing installation: Werkzeug 0.15.5\n",
      "    Uninstalling Werkzeug-0.15.5:\n",
      "      Successfully uninstalled Werkzeug-0.15.5\n",
      "  Found existing installation: tensorboard 1.14.0\n",
      "    Uninstalling tensorboard-1.14.0:\n",
      "      Successfully uninstalled tensorboard-1.14.0\n",
      "  Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "  Found existing installation: astor 0.8.0\n",
      "    Uninstalling astor-0.8.0:\n",
      "      Successfully uninstalled astor-0.8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found existing installation: tensorflow 1.14.0\n",
      "    Uninstalling tensorflow-1.14.0:\n",
      "      Successfully uninstalled tensorflow-1.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install tensorflow-gpu\n",
    "!pip install tensorflow\n",
    "!pip install pillow\n",
    "!pip install lxml\n",
    "!pip install Cython\n",
    "!pip install jupyter\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install opencv-python\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "#install protoc\n",
    "# Make sure you grab the latest version\n",
    "curl -OL https://github.com/google/protobuf/releases/download/v3.8.0/protoc-3.8.0-linux-x86_64.zip\n",
    "\n",
    "echo \"Unzip\"\n",
    "unzip -o protoc-3.8.0-linux-x86_64.zip -d protoc3\n",
    "\n",
    "echo \"Move protoc to /usr/local/bin/\"\n",
    "sudo cp -rf  protoc3/bin/* /usr/local/bin/\n",
    "\n",
    "echo \"Move protoc3/include to /usr/local/include/\"\n",
    "sudo cp -rf  protoc3/include/* /usr/local/include/\n",
    "\n",
    "echo \"Optional: change owner\"\n",
    "sudo chown $(whoami) /usr/local/bin/protoc\n",
    "sudo chown -R $(whoami) /usr/local/include/google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"~/dev/protoc3/bin\")\n",
    "print(sys.path)\n",
    "!protoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "mkdir TF_obj_detection_original\n",
    "#!mkdir TF_obj_detection_original/models\n",
    "#!mkdir TF_obj_detection_original/models/research\n",
    "#!mkdir TF_obj_detection_original/models/research/object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#5. Clone Object Detection API repository from GitHub https://github.com/tensorflow/models (here C:\\TF_obj_detection_original\\models)\n",
    "cd ..\n",
    "git clone https://github.com/tensorflow/models.git\n",
    "cp -r  ./models ./TF_obj_detection_original\n",
    "rm -r -f ./models\n",
    "#!ln -s ./models ./TF_obj_detection_original/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Download a pre-trained object detection models from the tensorflow model zoo git reposit.\n",
    "#Once the desired model is downloaded extract its contents to C:\\TF_obj_detection_original\\models\\research\\object_detection\n",
    "\n",
    "#!wget https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\n",
    "#!wget https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md -p ./TF_obj_detection_original/models/research/object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#8. Download the full repository located on this page (scroll to the top and click Clone or Download) and \n",
    "# extract all the contents directly into the C:\\TF_obj_detection_original\\models\\research\\object_detection directory. (You can overwrite the existing “README.md” file.)\n",
    "cd ..\n",
    "pwd\n",
    "git clone https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10.git\n",
    "cp --recursive  -v ./TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/* ./TF_obj_detection_original/models/research/object_detection\n",
    "rm --recursive -f ./TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Prepare training\n",
    "#9. Go to folder named research and then remove all the folders except Object Detection, Slim folders and set.py file.\n",
    "#!set base_dir = $pwd\n",
    "#!echo $base_dir\n",
    "cd ..\n",
    "pwd\n",
    "basedir=`pwd`\n",
    "echo $basedir\n",
    "#cd TF_obj_detection_original/models/research/\n",
    "pwd\n",
    "#rm  -f --verbose --recursive `!(\"./set.py\"|\"./object_detection/\"|\"./slim/\")`\n",
    "find ./TF_obj_detection_original/models/research/* -maxdepth 0 -type d -not \\( -name 'research' -name 'setup.py' -or  -name 'object_detection' -or -name 'slim' \\) -print0 | xargs -0  -I {} rm -r -v {}  #-delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#To train your own object detector, delete the following files (do not delete the folders):\n",
    "#1) All files in \\object_detection\\images\\train and \\object_detection\\images\\test\n",
    "#2) The “test_labels.csv” and “train_labels.csv” files in \\object_detection\\images\n",
    "#3) All files in \\object_detection\\training\n",
    "#4) All files in \\object_detection\\inference_graph\n",
    "cd ..\n",
    "rm -v ./TF_obj_detection_original/models/research/object_detection/images/train/*\n",
    "rm -v ./TF_obj_detection_original/models/research/object_detection/images/test/*\n",
    "rm -v ./TF_obj_detection_original/models/research/object_detection/images/*labels.csv\n",
    "rm -v ./TF_obj_detection_original/models/research/object_detection/training/*\n",
    "rm -v ./TF_obj_detection_original/models/research/object_detection/inference_graph/*\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10. 1) (tensorflow1) C:\\>set PYTHONPATH= C:\\TF_obj_detection_original\\models; C:\\TF_obj_detection_original\\models\\research; C:\\TF_obj_detection_original \\models\\research\\slim\n",
    "2) (tensorflow1) C:\\>set PATH=%PATH%;PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODOs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "11. Compile the Protobuf files, which are used by TensorFlow to configure model and training parameters. Every .proto file in the \\object_detection\\protos directory must be called out individually by the command.\n",
    "I created C:\\TF_obj_detection_original\\models\\research\\object_detection\\protos\\proto.bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#TODO\n",
    "pwd\n",
    "chmod u+x ./proto.sh\n",
    "cp ./proto.sh ../TF_obj_detection_original/models/research/object_detection/protos/proto.sh\n",
    "cp ./proto.sh ../TF_obj_detection_original/models/research/proto.sh\n",
    "cd ../TF_obj_detection_original/models/research/\n",
    "pwd\n",
    "export PATH=$PATH:~/dev/protoc3/bin\n",
    "# calling the shell script does not work. I cannot understand why...\n",
    "# ./proto.sh\n",
    "\n",
    "\n",
    "protoc --python_out=. ./object_detection/protos/anchor_generator.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/argmax_matcher.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/box_coder.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/box_predictor.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/eval.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/faster_rcnn.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/faster_rcnn_box_coder.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/grid_anchor_generator.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/hyperparams.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/image_resizer.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/input_reader.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/losses.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/matcher.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/mean_stddev_box_coder.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/model.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/optimizer.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/pipeline.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/post_processing.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/post_processing.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/preprocessor.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/region_similarity_calculator.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/square_box_coder.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/ssd.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/ssd_anchor_generator.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/string_int_label_map.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/train.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/keypoint_box_coder.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/multiscale_anchor_generator.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/graph_rewriter.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/flexible_grid_anchor_generator.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/bipartite_matcher.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/calibration.proto --proto_path=."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "12. Run the following commands from C:\\tensorflow1\\models\\research directory\n",
    "    1. (tensorflow1) C:\\TF_obj_detection_original\\models\\research> python setup.py build\n",
    "    2. (tensorflow1) C:\\TF_obj_detection_original\\models\\research> python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "cd ./TF_obj_detection_original/models/research\n",
    "python3 setup.py build\n",
    "#for this command root rights needed\n",
    "python3 setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "wget http://download.tensorflow.org/models/object_detection/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz\n",
    "pwd\n",
    "tar zxvf ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz -C ./TF_obj_detection_original/models/research/object_detection\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "13. Generate Training and Test Data\n",
    "Convert all the .xml files in both training and test folders into .csv files by using below command.\n",
    "(tensorflow1) C:\\TF_obj_detection_original\\models\\research\\object_detection> python xml_to_csv.py\n",
    "This creates a train_labels.csv and test_labels.csv file in the models\\research\\object_detection\\images directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "cd ./TF_obj_detection_original/models/research/object_detection\n",
    "python xml_to_csv.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "14. Generate .tf record\n",
    "Open the generate_tfrecord.py file from object_detection folder in a text editor. Replace the label map starting at line 31 with your own label map, where each object is assigned an ID number.\n",
    "Then, generate the TFRecord files by issuing these commands from the \\object_detection folder:\n",
    "    1. python generate_tfrecord.py — csv_input=imagestrain_labels.csv — image_dir=images\\train — output_path=train.record\n",
    "    2. python generate_tfrecord.py — csv_input=images\\test_labels.csv — image_dir=images\\test — output_path=test.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -r -f ../TF_obj_detection_original/models/research/object_detection/images\n",
    "unzip ./images.zip -d ../TF_obj_detection_original/models/research/object_detection\n",
    "echo \"Unzipped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp ./generate_tfrecord.py ../TF_obj_detection_original/models/research/object_detection/.\n",
    "cd ..\n",
    "cd ./TF_obj_detection_original/models/research/object_detection\n",
    "\n",
    "python3 generate_tfrecord.py --csv_input=./images/train_labels.csv --image_dir=./images/train --output_path=train.record\n",
    "python3 generate_tfrecord.py --csv_input=./images/test_labels.csv --image_dir=./images/test --output_path=test.record"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "15. Create Label Map and Configure Training\n",
    "The label map tells the trainer what each object is by defining a mapping of class names to class ID numbers. Use a text editor to create a new file and save it as labelmap.pbtxt in C:\\TF_obj_detection_original\\models\\research\\object_detection\\training folder the file type should be .pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp ./labelmap.pbtxt ../TF_obj_detection_original/models/research/object_detection/training"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "16. Configure Training\n",
    "The object detection training pipeline should be configured. It defines which model and what parameters will be used for training. Navigate to C:\\TF_obj_detection_original\\models\\research\\object_detection\\samples\\configs and copy the faster_rcnn_inception_v2_pets.config file into the \\research \\object_detection\\training directory.\n",
    "Open faster_rcnn_inception_v2_pets.config file in a text editor. Make some necessary changes to the .config file, mainly changing the number of classes and examples, and adding the file paths to the training data.\n",
    "Make the following changes to the faster_rcnn_inception_v2_pets.config file.\n",
    "· Line 9. Change num_classes to the number of different objects you want the classifier to detect. For the above shirt, t-shirt and jeans detector, it would be num_classes: 3.\n",
    "· Line 106. Change fine_tune_checkpoint to:\n",
    "o fine_tune_checkpoint: “C:\\TF_obj_detection_original/models/research/object_detection/\n",
    "o faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt”\n",
    "· Lines 123 and 125. In the train_input_reader section, change input_path and label_map_path to:\n",
    "o input_path: “C:\\TF_obj_detection_original/models/research/object_detection/train.record”\n",
    "o label_map_path: “C:\\TF_obj_detection_original/models/research/object_detection/training/labelmap.pbtxt”\n",
    "· Line 130. Change num_examples to the number of images you have in the \\images\\test directory.\n",
    "· Lines 135 and 137. In the eval_input_reader section, change input_path and label_map_path to:\n",
    "o input_path: “C:\\TF_obj_detection_original/models/research/object_detection/test.record”\n",
    "o label_map_path: “C:\\TF_obj_detection_original/models/research/object_detection/training/labelmap.pbtxt”\n",
    "Save the file after the changes have been made. The training job is all configured and ready to run.\n",
    "Model Training: In the \\object_detection path put the following command to begin the training.\n",
    "python train.py  --logtostderr — train_dir=training/ — pipeline_config_path=training/faster_rcnn_inception_v2_pets.config\n",
    "\n",
    "C:\\TF_obj_detection_original\\models\\research\\object_detection>tensorboard  --logdir=training\n",
    "\n",
    "\n",
    "To get result:\n",
    "python \"C:\\Users\\srastatu\\New folder\\SSD.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#TODO\n",
    "pwd\n",
    "cp ./*.config ../TF_obj_detection_original/models/research/object_detection/training\n",
    "cp ./train.py ../TF_obj_detection_original/models/research\n",
    "cd ../TF_obj_detection_original/models/research/object_detection\n",
    "cd ..\n",
    "\n",
    "researchdir=$(pwd)\n",
    "echo $researchdir\n",
    "\n",
    "export PATH=$PATH:$researchdir/slim\n",
    "\n",
    "export PYTHONPATH=$researchdir:$researchdir/slim\n",
    "echo $PYTHONPATH\n",
    "#--logtostderr\n",
    "python3 ./train.py  --train_dir=./object_detection/training --pipeline_config_path=./object_detection/training/SSD_resnet50.config > my.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
