{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager().update('notebook', {'limit_output': 100})\n",
    "cm = ConfigManager().update('notebook', {'client_max_body_size': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/4stanislav/tfstuffwithkubeflow1/framework\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "homeDir = os.getcwd() + \"/framework\"\n",
    "if not os.path.exists(homeDir):\n",
    "    os.makedirs(homeDir)\n",
    "print (homeDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$homeDir\" \n",
    "cd $1\n",
    "rm -rf models\n",
    "rm -rf TF_obj_detection_original\n",
    "rm -rf ~/.local/share/Trash/*\n",
    "echo \"Cleaned\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already up-to-date: pip in /opt/conda/lib/python3.6/site-packages (19.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
      "\u001b[K     |▌                               | 1.6MB 2.7MB/s eta 0:00:40"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install tensorflow-gpu\n",
    "!pip install tensorflow\n",
    "!pip install pillow\n",
    "!pip install lxml\n",
    "!pip install Cython\n",
    "!pip install jupyter\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install opencv-python\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$homeDir\" \n",
    "cd $1\n",
    "#install protoc\n",
    "# Make sure you grab the latest version\n",
    "curl -OL https://github.com/google/protobuf/releases/download/v3.8.0/protoc-3.8.0-linux-x86_64.zip\n",
    "\n",
    "echo \"Unzip\"\n",
    "unzip -o protoc-3.8.0-linux-x86_64.zip -d protoc3\n",
    "\n",
    "echo \"Move protoc to /usr/local/bin/\"\n",
    "sudo cp -rf  protoc3/bin/* /usr/local/bin/\n",
    "\n",
    "echo \"Move protoc3/include to /usr/local/include/\"\n",
    "sudo cp -rf  protoc3/include/* /usr/local/include/\n",
    "\n",
    "echo \"Optional: change owner\"\n",
    "sudo chown $(whoami) /usr/local/bin/protoc\n",
    "sudo chown -R $(whoami) /usr/local/include/google"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"~/dev/protoc3/bin\")\n",
    "print(sys.path)\n",
    "!protoc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_obj_detection_originalDir = homeDir + \"/TF_obj_detection_original\"\n",
    "if not os.path.exists(TF_obj_detection_originalDir):\n",
    "    os.makedirs(TF_obj_detection_originalDir)\n",
    "if not os.path.exists(TF_obj_detection_originalDir + \"/models\"):\n",
    "    os.makedirs(TF_obj_detection_originalDir + \"/models\")\n",
    "if not os.path.exists(TF_obj_detection_originalDir + \"/models/research\"):\n",
    "    os.makedirs(TF_obj_detection_originalDir + \"/models/research\")\n",
    "if not os.path.exists(TF_obj_detection_originalDir + \"/models/research/object_detection\"):\n",
    "    os.makedirs(TF_obj_detection_originalDir + \"/models/research/object_detection\")\n",
    "\n",
    "#%%bash -s \"$homeDir\" \n",
    "#cd $1\n",
    "#mkdir TF_obj_detection_original\n",
    "#!mkdir TF_obj_detection_original/models\n",
    "#!mkdir TF_obj_detection_original/models/research\n",
    "#!mkdir TF_obj_detection_original/models/research/object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$homeDir\" \n",
    "cd $1\n",
    "#5. Clone Object Detection API repository from GitHub https://github.com/tensorflow/models (here C:\\TF_obj_detection_original\\models)\n",
    "#cd ..\n",
    "git clone https://github.com/tensorflow/models.git\n",
    "cp -r  ./models ./TF_obj_detection_original\n",
    "rm -r -f ./models\n",
    "#!ln -s ./models ./TF_obj_detection_original/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Download a pre-trained object detection models from the tensorflow model zoo git reposit.\n",
    "#Once the desired model is downloaded extract its contents to C:\\TF_obj_detection_original\\models\\research\\object_detection\n",
    "\n",
    "#!wget https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\n",
    "#!wget https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md -p ./TF_obj_detection_original/models/research/object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$homeDir\" \n",
    "cd $1\n",
    "#8. Download the full repository located on this page (scroll to the top and click Clone or Download) and \n",
    "# extract all the contents directly into the C:\\TF_obj_detection_original\\models\\research\\object_detection directory. (You can overwrite the existing “README.md” file.)\n",
    "pwd\n",
    "git clone https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10.git\n",
    "cp --recursive  -v ./TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/* ./TF_obj_detection_original/models/research/object_detection\n",
    "rm --recursive -f ./TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$homeDir\" \n",
    "cd $1\n",
    "#Prepare training\n",
    "#9. Go to folder named research and then remove all the folders except Object Detection, Slim folders and set.py file.\n",
    "#!set base_dir = $pwd\n",
    "#!echo $base_dir\n",
    "#cd ..\n",
    "pwd\n",
    "basedir=`pwd`\n",
    "echo $basedir\n",
    "#cd TF_obj_detection_original/models/research/\n",
    "pwd\n",
    "#rm  -f --verbose --recursive `!(\"./set.py\"|\"./object_detection/\"|\"./slim/\")`\n",
    "find ./TF_obj_detection_original/models/research/* -maxdepth 0 -type d -not \\( -name 'research' -name 'setup.py' -or  -name 'object_detection' -or -name 'slim' \\) -print0 | xargs -0  -I {} rm -r -v {}  #-delete"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$homeDir\" \n",
    "cd $1\n",
    "#To train your own object detector, delete the following files (do not delete the folders):\n",
    "#1) All files in \\object_detection\\images\\train and \\object_detection\\images\\test\n",
    "#2) The “test_labels.csv” and “train_labels.csv” files in \\object_detection\\images\n",
    "#3) All files in \\object_detection\\training\n",
    "#4) All files in \\object_detection\\inference_graph\n",
    "#cd ..\n",
    "rm ./TF_obj_detection_original/models/research/object_detection/images/train/*\n",
    "rm ./TF_obj_detection_original/models/research/object_detection/images/test/*\n",
    "rm ./TF_obj_detection_original/models/research/object_detection/images/*labels.csv\n",
    "rm ./TF_obj_detection_original/models/research/object_detection/training/*\n",
    "rm ./TF_obj_detection_original/models/research/object_detection/inference_graph/*\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10. 1) (tensorflow1) C:\\>set PYTHONPATH= C:\\TF_obj_detection_original\\models; C:\\TF_obj_detection_original\\models\\research; C:\\TF_obj_detection_original \\models\\research\\slim\n",
    "2) (tensorflow1) C:\\>set PATH=%PATH%;PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODOs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "11. Compile the Protobuf files, which are used by TensorFlow to configure model and training parameters. Every .proto file in the \\object_detection\\protos directory must be called out individually by the command.\n",
    "I created C:\\TF_obj_detection_original\\models\\research\\object_detection\\protos\\proto.bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$homeDir\" \n",
    "cd $1\n",
    "#TODO\n",
    "pwd\n",
    "chmod u+x ../proto.sh\n",
    "cp ../proto.sh $1/TF_obj_detection_original/models/research/object_detection/protos/proto.sh\n",
    "cp ../proto.sh $1/TF_obj_detection_original/models/research/proto.sh\n",
    "cd $1/TF_obj_detection_original/models/research/\n",
    "pwd\n",
    "export PATH=$PATH:~/dev/protoc3/bin\n",
    "# calling the shell script does not work. I cannot understand why...\n",
    "# ./proto.sh\n",
    "echo \"Start to protoc\"\n",
    "protoc --python_out=. ./object_detection/protos/anchor_generator.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/argmax_matcher.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/box_coder.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/box_predictor.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/eval.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/faster_rcnn.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/faster_rcnn_box_coder.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/grid_anchor_generator.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/hyperparams.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/image_resizer.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/input_reader.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/losses.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/matcher.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/mean_stddev_box_coder.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/model.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/optimizer.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/pipeline.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/post_processing.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/post_processing.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/preprocessor.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/region_similarity_calculator.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/square_box_coder.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/ssd.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/ssd_anchor_generator.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/string_int_label_map.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/train.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/keypoint_box_coder.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/multiscale_anchor_generator.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/graph_rewriter.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/flexible_grid_anchor_generator.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/bipartite_matcher.proto --proto_path=.\n",
    "protoc --python_out=. ./object_detection/protos/calibration.proto --proto_path=.\n",
    "echo \"End to protoc\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "12. Run the following commands from C:\\tensorflow1\\models\\research directory\n",
    "    1. (tensorflow1) C:\\TF_obj_detection_original\\models\\research> python setup.py build\n",
    "    2. (tensorflow1) C:\\TF_obj_detection_original\\models\\research> python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$homeDir\" \n",
    "cd $1\n",
    "cd ./TF_obj_detection_original/models/research\n",
    "#for this command root rights needed\n",
    "python3 setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$homeDir\" \n",
    "cd $1\n",
    "wget http://download.tensorflow.org/models/object_detection/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz\n",
    "pwd\n",
    "tar zxvf ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz -C ./TF_obj_detection_original/models/research/object_detection\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "13. Generate Training and Test Data\n",
    "Convert all the .xml files in both training and test folders into .csv files by using below command.\n",
    "(tensorflow1) C:\\TF_obj_detection_original\\models\\research\\object_detection> python xml_to_csv.py\n",
    "This creates a train_labels.csv and test_labels.csv file in the models\\research\\object_detection\\images directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$homeDir\" \n",
    "cd $1\n",
    "cd ./TF_obj_detection_original/models/research/object_detection\n",
    "python xml_to_csv.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "14. Generate .tf record\n",
    "Open the generate_tfrecord.py file from object_detection folder in a text editor. Replace the label map starting at line 31 with your own label map, where each object is assigned an ID number.\n",
    "Then, generate the TFRecord files by issuing these commands from the \\object_detection folder:\n",
    "    1. python generate_tfrecord.py — csv_input=imagestrain_labels.csv — image_dir=images\\train — output_path=train.record\n",
    "    2. python generate_tfrecord.py — csv_input=images\\test_labels.csv — image_dir=images\\test — output_path=test.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$homeDir\" \n",
    "cd $1\n",
    "rm -r -f ./TF_obj_detection_original/models/research/object_detection/images\n",
    "unzip ../images.zip -d ./TF_obj_detection_original/models/research/object_detection\n",
    "echo \"Unzipped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$homeDir\" \n",
    "cd $1\n",
    "cp ../generate_tfrecord.py ./TF_obj_detection_original/models/research/object_detection/.\n",
    "#cd ..\n",
    "cd ./TF_obj_detection_original/models/research/object_detection\n",
    "\n",
    "python3 generate_tfrecord.py --csv_input=./images/train_labels.csv --image_dir=./images/train --output_path=train.record\n",
    "python3 generate_tfrecord.py --csv_input=./images/test_labels.csv --image_dir=./images/test --output_path=test.record"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "15. Create Label Map and Configure Training\n",
    "The label map tells the trainer what each object is by defining a mapping of class names to class ID numbers. Use a text editor to create a new file and save it as labelmap.pbtxt in C:\\TF_obj_detection_original\\models\\research\\object_detection\\training folder the file type should be .pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$homeDir\" \n",
    "cd $1\n",
    "cp ../labelmap.pbtxt ./TF_obj_detection_original/models/research/object_detection/training"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "16. Configure Training\n",
    "The object detection training pipeline should be configured. It defines which model and what parameters will be used for training. Navigate to C:\\TF_obj_detection_original\\models\\research\\object_detection\\samples\\configs and copy the faster_rcnn_inception_v2_pets.config file into the \\research \\object_detection\\training directory.\n",
    "Open faster_rcnn_inception_v2_pets.config file in a text editor. Make some necessary changes to the .config file, mainly changing the number of classes and examples, and adding the file paths to the training data.\n",
    "Make the following changes to the faster_rcnn_inception_v2_pets.config file.\n",
    "· Line 9. Change num_classes to the number of different objects you want the classifier to detect. For the above shirt, t-shirt and jeans detector, it would be num_classes: 3.\n",
    "· Line 106. Change fine_tune_checkpoint to:\n",
    "o fine_tune_checkpoint: “C:\\TF_obj_detection_original/models/research/object_detection/\n",
    "o faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt”\n",
    "· Lines 123 and 125. In the train_input_reader section, change input_path and label_map_path to:\n",
    "o input_path: “C:\\TF_obj_detection_original/models/research/object_detection/train.record”\n",
    "o label_map_path: “C:\\TF_obj_detection_original/models/research/object_detection/training/labelmap.pbtxt”\n",
    "· Line 130. Change num_examples to the number of images you have in the \\images\\test directory.\n",
    "· Lines 135 and 137. In the eval_input_reader section, change input_path and label_map_path to:\n",
    "o input_path: “C:\\TF_obj_detection_original/models/research/object_detection/test.record”\n",
    "o label_map_path: “C:\\TF_obj_detection_original/models/research/object_detection/training/labelmap.pbtxt”\n",
    "Save the file after the changes have been made. The training job is all configured and ready to run.\n",
    "Model Training: In the \\object_detection path put the following command to begin the training.\n",
    "python train.py  --logtostderr — train_dir=training/ — pipeline_config_path=training/faster_rcnn_inception_v2_pets.config\n",
    "\n",
    "C:\\TF_obj_detection_original\\models\\research\\object_detection>tensorboard  --logdir=training\n",
    "\n",
    "\n",
    "To get result:\n",
    "python \"C:\\Users\\srastatu\\New folder\\SSD.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$homeDir\" \n",
    "cd $1\n",
    "#TODO\n",
    "pwd\n",
    "cp ../*.config ./TF_obj_detection_original/models/research/object_detection/training\n",
    "cp ../train.py ./TF_obj_detection_original/models/research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$homeDir\" \n",
    "cd $1\n",
    "\n",
    "cd ./TF_obj_detection_original/models/research/object_detection\n",
    "cd ..\n",
    "\n",
    "researchdir=$(pwd)\n",
    "echo $researchdir\n",
    "\n",
    "export PATH=$PATH:$researchdir/slim\n",
    "\n",
    "export PYTHONPATH=$researchdir:$researchdir/slim\n",
    "echo $PYTHONPATH\n",
    "#--logtostderr\n",
    "python3 ./train.py  --train_dir=./object_detection/training --pipeline_config_path=./object_detection/training/SSD_resnet50.config > my.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
